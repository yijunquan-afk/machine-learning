# æœºå™¨å­¦ä¹ â€”â€”04æœ´ç´ è´å¶æ–¯

## å‚è€ƒèµ„æ–™

1. [AIlearning](https://ailearning.apachecn.org/#/docs/ml/2)
2. [Machine-Learning-in-Action](https://github.com/TeFuirnever/Machine-Learning-in-Action)
3. åºå–„æ°‘.è¥¿å®‰äº¤é€šå¤§å­¦æœºå™¨å­¦ä¹ å¯¼è®º2022æ˜¥PPT

æ›´å¤šåŸç†è¯·å‚è€ƒæœ¬äººå¦ä¸€ç¯‡åšå®¢ï¼š[[æœºå™¨å­¦ä¹ å¯¼è®º]â€”â€”ç¬¬å…­è¯¾â€”â€”è´å¶æ–¯åˆ†ç±»å™¨](https://blog.csdn.net/weixin_47692652/article/details/124309268)

ä½¿ç”¨Jupyterè¿›è¡Œç»ƒä¹ ï¼Œpython3

## ä¸€ã€çŸ¥è¯†å‡†å¤‡

### è´å¶æ–¯å…¬å¼

é’ˆå¯¹ä¸¤ä¸ªéšæœºå˜é‡ï¼Œè”åˆæ¦‚ç‡åˆ†å¸ƒå…·æœ‰ä¸¤ç§åˆ†è§£å½¢å¼
$$
P(x,y)=P(x|y)P(y)=P(y|x)P(x)
$$
å› æ­¤ï¼Œåˆ©ç”¨ä¸Šå¼å¾—åˆ°è´å¶æ–¯å…¬å¼

$$
P(c|x)=\frac{P(x|c)P(c)}{P(x)}
$$

é€šè¿‡è´å¶æ–¯å…¬å¼å¾—åˆ°è´å¶æ–¯å†³ç­–ç†è®ºåŸºæœ¬æ€æƒ³ï¼š

1ï¸âƒ£ å·²çŸ¥**ç±»æ¡ä»¶æ¦‚ç‡**å¯†åº¦å‚æ•°è¡¨è¾¾å¼$P(x|c)$å’Œ**å…ˆéªŒæ¦‚ç‡**$P(c)$

2ï¸âƒ£ åˆ©ç”¨è´å¶æ–¯å…¬å¼è½¬æ¢æˆ**åéªŒæ¦‚ç‡**

3ï¸âƒ£ æ ¹æ®åéªŒæ¦‚ç‡å¤§å°è¿›è¡Œå†³ç­–åˆ†ç±»

> **å…ˆéªŒæ¦‚ç‡ï¼ˆprior probabilityï¼‰**ï¼šæŒ‡æ ¹æ®ä»¥å¾€ç»éªŒå’Œåˆ†æã€‚åœ¨å®éªŒæˆ–é‡‡æ ·å‰å°±å¯ä»¥å¾—åˆ°çš„æ¦‚ç‡ã€‚
>
> **åéªŒæ¦‚ç‡ï¼ˆposterior probabilityï¼‰**ï¼šæŒ‡æŸä»¶äº‹å·²ç»å‘ç”Ÿï¼Œæƒ³è¦è®¡ç®—è¿™ä»¶äº‹å‘ç”Ÿçš„åŸå› æ˜¯ç”±æŸä¸ªå› ç´ å¼•èµ·çš„æ¦‚ç‡ã€‚
>
> **ç±»æ¡ä»¶æ¦‚ç‡å¯†åº¦**æ˜¯ï¼Œå‡å®šxæ˜¯ä¸€ä¸ªè¿ç»­éšæœºå˜é‡ï¼Œå…¶åˆ†å¸ƒå–å†³äºç±»åˆ«çŠ¶æ€ï¼Œè¡¨ç¤ºæˆp(x|Ï‰)çš„å½¢å¼ï¼Œè¿™å°±æ˜¯â€œç±»æ¡ä»¶æ¦‚ç‡å¯†åº¦â€å‡½æ•°ï¼Œå³**ç±»åˆ«çŠ¶æ€ä¸ºÏ‰æ—¶çš„xçš„**[æ¦‚ç‡å¯†åº¦å‡½æ•°](https://baike.baidu.com/item/æ¦‚ç‡å¯†åº¦å‡½æ•°/5021996)ï¼ˆæœ‰æ—¶ä¹Ÿç§°ä¸ºçŠ¶æ€æ¡ä»¶æ¦‚ç‡å¯†åº¦ï¼‰ã€‚

### è´å¶æ–¯å†³ç­–åŸºç¡€

è´å¶æ–¯åˆ†ç±»å†³ç­–åˆ©ç”¨æ¦‚ç‡å¯¹æ•°æ®è¿›è¡Œå»ºæ¨¡ï¼Œä»è€ŒåŸºäº**è´å¶æ–¯å®šç†**ç»™å‡ºåˆ†ç±»é¢„æµ‹çš„ä¸ç¡®å®šæ€§

å°†ç‰¹å¾å‘é‡$x=(x_1,...,x_p)^T$ç±»åˆ«æ ‡ç­¾ğ‘ğ‘—ä½œä¸º**éšæœºå˜é‡**

ç»™å®šæ ·æœ¬ğ’™,åŸºäºæ¡ä»¶ï¼ˆåéªŒï¼‰æ¦‚ç‡$P(c_i|x)$è®¡ç®—å°†æ ·æœ¬ğ’™åˆ†ç±»ä¸ºğ‘ğ‘–æ‰€äº§ç”Ÿçš„æœŸæœ›æŸå¤±
$$
R(c_i|\pmb x)= \sum_{j=1}^L\lambda_{ij}P(c_j|\pmb x)
$$
å…¶ä¸­,$\lambda_{ij}$æ˜¯å°†ä¸€ä¸ªçœŸå®æ ‡è®°ä¸º$c_j$çš„æ ·æœ¬è¯¯åˆ†ç±»ä¸º$c_i$æ‰€äº§ç”Ÿçš„æŸå¤±

è´å¶æ–¯åˆ¤å®šå‡†åˆ™è¦æ±‚ <mark>æœŸæœ›æŸå¤±è¾¾åˆ°æœ€å° </mark>ã€‚
$$
h^*(x)=\text{argmin}\ R(c|x)
$$
ç§°$h^*(x)$ä¸ºè´å¶æ–¯æœ€ä¼˜åˆ†ç±»å™¨

è¿›ä¸€æ­¥ï¼Œè‹¥ç›®æ ‡æ˜¯æœ€å°åŒ–åˆ†ç±»é”™è¯¯ç‡ï¼Œåˆ™

![image-20220321171559820](https://img-blog.csdnimg.cn/img_convert/f44f6a3401e67dedb196f3fb6aa7b142.png)

æœŸæœ›æŸå¤±å¯ä»¥å†™æˆ
$$
R(c_i|x)=P(c_1|x)+...+P(c_{i-1}|x)+P(c_{i+1}|x)+...+P(c_{L}|x)=1-P(c_i|x)
$$
äºæ˜¯ï¼Œå¯¹æ¯ä¸ªæ ·æœ¬ï¼Œé€‰æ‹©ä½¿**åéªŒæ¦‚ç‡æœ€å¤§çš„ç±»åˆ«æ ‡è®°**
$$
c_{MAP}=\underset{c_j\in C}{\text{argmax}}\ P(c_j|x_1,x_2,...,x_p)
$$

## äºŒã€MAPåˆ†ç±»å‡†åˆ™

ä¼°è®¡åéªŒæ¦‚ç‡ğ‘ƒ(ğ‘|ğ‘¥)çš„æ–¹æ³•ä¸»è¦æœ‰ä¸¤ç§ç­–ç•¥ï¼š

1ï¸âƒ£ **åˆ¤åˆ«å¼æ¨¡å‹**ï¼šé€šè¿‡å¯¹ğ‘ƒ(ğ‘|ğ‘¥)ç›´æ¥å»ºæ¨¡é¢„æµ‹
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/d47ac1f949fc4706adee757efaaeccd8.png)

é€»è¾‘å›å½’ï¼š
$$
P(c|x;\theta)=(f_\theta(x))^c(1-f_\theta(x))^{1-c}\\
c\in{0,1}\ f_{\theta}(x)=\frac{1}{1+e^{-\theta^Tx}}
$$
**ç›´æ¥å¯¹æ¡ä»¶æ¦‚ç‡å»ºæ¨¡ï¼Œä¸å…³å¿ƒèƒŒåçš„æ•°æ®åˆ†å¸ƒ**$P(x,c)$

2ï¸âƒ£ **ç”Ÿæˆå¼æ¨¡å‹**ï¼šä½¿ç”¨è´å¶æ–¯æ¨ç†é¢„æµ‹ï¼Œå³å‡å®šç±»æ¡ä»¶æ¦‚ç‡å…·æœ‰æŸç§ç¡®å®šçš„æ¦‚ç‡åˆ†å¸ƒ

![image-20220321171808451](https://img-blog.csdnimg.cn/img_convert/39af1b5b73a151f71f9805fc6ec3040c.png)

å…ˆå¯¹è”åˆæ¦‚ç‡åˆ†å¸ƒğ‘ƒ(ğ‘¥,ğ‘)å»ºæ¨¡ï¼Œå†é€šè¿‡è´å¶æ–¯å…¬å¼è®¡ç®—åéªŒæ¦‚ç‡ğ‘ƒ(ğ‘|ğ‘¥)

![image-20220420162438848](https://img-blog.csdnimg.cn/img_convert/1a7db8476e399864e298c90ddcd2cf0f.png)

å…ˆå¯¹è”åˆæ¦‚ç‡åˆ†å¸ƒ ğ‘ƒ(ğ‘¥, ğ‘) å»ºæ¨¡ï¼Œå†é€šè¿‡è´å¶æ–¯å…¬å¼è®¡ç®—åéªŒæ¦‚ç‡ ğ‘ƒ( ğ‘| ğ‘¥)

GANsï¼šé€‚ç”¨äºå¨±ä¹è¡Œä¸š

## ä¸‰ã€è´å¶æ–¯åˆ†ç±»ç®—æ³•

### ä¸€èˆ¬ç”Ÿæˆå¼è´å¶æ–¯åˆ†ç±»å™¨

#### å…¬å¼è¯´æ˜

åŸºäºè´å¶æ–¯å…¬å¼ä¼°è®¡åéªŒæ¦‚ç‡ï¼š

![image-20220321172252379](https://img-blog.csdnimg.cn/img_convert/00d8c5a949c2793556f554caa3b48e2c.png)

ä½¿ç”¨æœ€å¤§åéªŒæ¦‚ç‡å‡†åˆ™ç»™å‡ºç±»æ ‡ç­¾

![image-20220321172306382](https://img-blog.csdnimg.cn/img_convert/29b291369166c466894ecad453b5ec27.png)

#### ä¸¾ä¾‹è¯´æ˜

ä¾‹å­ï¼šä»Šå¤©æˆ‘ä»¬å¯ä»¥æ‰“ç½‘çƒå—ï¼Ÿ

è®­ç»ƒç¤ºä¾‹é›†å¦‚ä¸‹

![image-20220420164325967](https://img-blog.csdnimg.cn/img_convert/3e4e52f5ae2de131ff9769662366175f.png)

å¦‚æœç»™ä¸€ä¸ªæ–°æ ·æœ¬ï¼šX = (å¤©æ°”  = æ™´, æ°”æ¸©  = å†·, æ¹¿åº¦  = é«˜, é£  = æœ‰)ï¼Œæƒ³çŸ¥é“æ˜¯å¦å¯ä»¥æ‰“ç½‘çƒï¼Ÿ

ä¾æ®å¤§æ•°å®šå¾‹ï¼Œåˆ©ç”¨æ ·æœ¬å‡ºç°é¢‘ç‡ä¼°è®¡å…ˆéªŒæ¦‚ç‡

> åœ¨è¯•éªŒä¸å˜çš„æ¡ä»¶ä¸‹ï¼Œé‡å¤è¯•éªŒå¤šæ¬¡ï¼Œéšæœºäº‹ä»¶çš„é¢‘ç‡è¿‘ä¼¼äºå®ƒçš„æ¦‚ç‡ã€‚å¶ç„¶ä¸­åŒ…å«ç€æŸç§å¿…ç„¶ã€‚

![image-20220420164601250](https://img-blog.csdnimg.cn/img_convert/2c12d30feaeda2732c5d5635f95f5ef4.png)

å…¶æ¬¡ï¼Œä¼°è®¡ç±»æ¡ä»¶æ¦‚ç‡

![image-20220420164825761](https://img-blog.csdnimg.cn/img_convert/6bef4d5570deab813a69ccab0ef28e52.png)

æ ¹æ®æ ·æœ¬å‡ºç°é¢‘ç‡ä¼°è®¡æ¡ä»¶æ¦‚ç‡ã€‚ä½†ç”±äºæ ·æœ¬æ•°è¿œå°äºéšæœºå‘é‡çš„å¯èƒ½å–å€¼æ•°ç›®ï¼Œä¼°è®¡å€¼é€šå¸¸ä¸å¯é 

> ä¾‹å¦‚ï¼š$P(å¤šäº‘ï¼Œçƒ­ï¼Œé«˜ï¼Œæ— |Yes)=\frac{1}{9}\qquad P(å¤šäº‘ï¼Œçƒ­ï¼Œé«˜ï¼Œæ— |Yes)=\frac{0}{5}$
>
> <mark>æœªè§‚æµ‹åˆ°â‰ å‡ºç°æ¦‚ç‡ä¸º0</mark>

**è®­ç»ƒè¿‡ç¨‹**

**è·å¾—å…ˆéªŒæ¦‚ç‡**
$$
P(X=Yes)=\frac{9}{14}\qquad P(C=No)=\frac{5}{14}
$$
**å¾—åˆ°ç±»æ¡ä»¶æ¦‚ç‡è¡¨**

![image-20220420165625019](https://img-blog.csdnimg.cn/img_convert/23c6905c9a4e7887fdb8f03c86a3f8b6.png)

**æµ‹è¯•é˜¶æ®µ**

ç»™å®šæµ‹è¯•æ ·æœ¬ï¼šX = (å¤©æ°” = æ™´, æ°”æ¸© = å†·, æ¹¿åº¦ = é«˜, é£ = æœ‰)ï¼Œ é€šè¿‡æŸ¥æ‰¾æ¡ä»¶æ¦‚ç‡è¡¨ï¼Œå¯ä»¥å¾—åˆ°
$$
P(X|Yes)P(C=Yes)=\frac{0}{9}\times =\frac{9}{14}=0\\
P(X|No)P(C=No)=\frac{0}{5}\times =\frac{5}{14}=0\\
$$
ç”±æ­¤ï¼ŒåŸºäºè´å¶æ–¯å…¬å¼:
$$
P(Yes|X)=0\qquad P(No|X)=0
$$
<mark>æ‰“å’Œä¸æ‰“éƒ½æ˜¯0ï¼Œæ•ˆæœä¸å¥½ï¼</mark>

### æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨

#### å…¬å¼è¯´æ˜

æœ´ç´ è´å¶æ–¯åˆ†ç±»ï¼šå¯¹å·²çŸ¥ç±»åˆ«ï¼Œ**å‡è®¾æ‰€æœ‰å±æ€§ç›¸äº’ç‹¬ç«‹**ï¼ˆå±æ€§æ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾ï¼‰

![image-20220321173421760](https://img-blog.csdnimg.cn/img_convert/20df58d7296002948cb34deb6e4e3fe0.png)

å› æ­¤æœ´ç´ è´å¶æ–¯çš„åˆ†ç±»å…¬å¼ä¸ºï¼š

![image-20220321173455253](https://img-blog.csdnimg.cn/img_convert/4f12b1a2e25d71b380decff26d090fff.png)

åœ¨è®­ç»ƒæ—¶ï¼Œæœ´ç´ è´å¶æ–¯ä¸ºæ¯ä¸ªå±æ€§ä¼°è®¡æ¡ä»¶æ¦‚ç‡$P(x_i|c_j)$

å‡è®¾æ ·æœ¬çš„ğ‘ä¸ªå±æ€§éƒ½æœ‰ğ‘‘ç§å¯èƒ½å–å€¼ï¼Œåˆ™å…±éœ€è¦ä¼°è®¡ğ‘‘ğ‘ä¸ªæ¡ä»¶æ¦‚ç‡

> æœ´ç´ è´å¶æ–¯çš„æœ´ç´ ä½“ç°åœ¨å…¶å¯¹å„ä¸ªæ¡ä»¶çš„ç‹¬ç«‹æ€§å‡è®¾ä¸Šï¼ŒåŠ ä¸Šç‹¬ç«‹å‡è®¾åï¼Œå¤§å¤§å‡å°‘äº†å‚æ•°çš„å‡è®¾ç©ºé—´ï¼šä»$d^p$é™åˆ°äº†ğ‘‘ğ‘ã€‚

#### ä¸¾ä¾‹è¯´æ˜

ä¾‹å­ï¼šä»Šå¤©æˆ‘ä»¬å¯ä»¥æ‰“ç½‘çƒå—ï¼Ÿ

è®­ç»ƒç¤ºä¾‹é›†å¦‚ä¸‹

![image-20220420164325967](https://img-blog.csdnimg.cn/img_convert/3e4e52f5ae2de131ff9769662366175f.png)

å¦‚æœç»™ä¸€ä¸ªæ–°æ ·æœ¬ï¼šX = (å¤©æ°”  = æ™´, æ°”æ¸©  = å†·, æ¹¿åº¦  = é«˜, é£  = æœ‰)ï¼Œæƒ³çŸ¥é“æ˜¯å¦å¯ä»¥æ‰“ç½‘çƒï¼Ÿ

**éœ€è¦ä¼°è®¡**

> å…ˆéªŒ$P(C=c_j)$
>
> æ¯ä¸ªå±æ€§çš„æ¡ä»¶æ¦‚ç‡$P(x_i|c_j)$

ä½¿ç”¨æ ·æœ¬å‡ºç°çš„æ¦‚ç‡
$$
\hat{P}(c_j)=\frac{N(C=c_j)}{N}\\
\hat{P}(x_i|c_j)=\frac{N(X_i=x_i,C=c_j)}{N(C=c_j)}
$$
å¯¹äºæ‰“ç½‘çƒé—®é¢˜ï¼Œæœ‰

å…ˆéªŒæ¦‚ç‡ï¼š
$$
P(C=Yes)=9/14\qquad P(C=No)=5/14
$$
æ¡ä»¶æ¦‚ç‡$P(X_i|C_j)$

![image-20220420203005417](https://img-blog.csdnimg.cn/img_convert/9695cbfb0c5aedeecd22c0533ab011bb.png)

æµ‹è¯•æ­¥éª¤

> :one: ç»™å®šæ–°æ ·æœ¬ï¼šX = (å¤©æ°” = æ™´, æ°”æ¸© = å†·, æ¹¿åº¦ = é«˜, é£ = æœ‰)
>
> :two: æŸ¥å…ˆéªŒå’Œæ¡ä»¶æ¦‚ç‡è¡¨
> $$
> P(C=Yes)=9/14\qquad P(C=No)=5/14
> $$
> ![image-20220420203149604](https://img-blog.csdnimg.cn/img_convert/8a952e189cc59ec370324b67fb6e43a4.png)
>
> :three: è®¡ç®—åéªŒæ¦‚ç‡
>
> ![image-20220420203315992](https://img-blog.csdnimg.cn/img_convert/600b38451841f9f3261981d7bfd72659.png)
>
> :four: å› ä¸ºP(Yes|x)<P(No|x)ï¼Œæ ¹æ®MAPå‡†åˆ™ï¼Œé¢„æµ‹ä¸º"ä¸æ‰“ç½‘çƒ"

#### é¿å…0æ¦‚ç‡é—®é¢˜

è‹¥æŸä¸ªå±æ€§å€¼åœ¨è®­ç»ƒé›†ä¸­æ²¡æœ‰ä¸æŸä¸ªç±»åŒæ—¶å‡ºç°è¿‡ï¼Œåˆ™åŸºäºé¢‘ç‡çš„æ¦‚ç‡ä¼°è®¡å°†ä¸ºé›¶

ä¸åˆç†ï¼šä»…ä»…å› ä¸ºäº‹ä»¶ä¹‹å‰æ²¡æœ‰å‘ç”Ÿè¿‡ï¼Œå¹¶ä¸æ„å‘³ç€å®ƒä¸ä¼šå‘ç”Ÿï¼Œä¸ºé¿å…è¿™ä¸€æƒ…å†µï¼Œ**éœ€è¦å¯¹æ¦‚ç‡å€¼è¿›è¡Œå¹³æ»‘**

è§£å†³æ–¹æ¡ˆï¼š**ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯æ ¡æ­£**
$$
\hat{P}(c_j)=\frac{N(C=c_j)+1}{N+|C|}\\
\hat{P}(x_i|c_j)=\frac{N(X_i=x_i,C=c_j)+1}{N(C=c_j)+|X_i|}\\
|C|\rightarrow ç±»çš„ä¸ªæ•°\qquad |X_i|\rightarrow å±æ€§çš„å–å€¼æ•°ç›®
$$
ä¾‹å¦‚ï¼š

![image-20220420203712736](https://img-blog.csdnimg.cn/img_convert/4b4aab80874123a11c88922ee3eecf28.png)
$$
P(X_1=å¤šäº‘|C=No)=\frac{0+1}{5+3}=\frac{1}{8}
$$
é¿å…äº†å› è®­ç»ƒæ ·æœ¬ä¸è¶³è€Œå¯¼è‡´çš„æ¦‚ç‡ä¼°å€¼ä¸º0çš„é—®é¢˜ã€‚

## å››ã€æœ´ç´ è´å¶æ–¯åº”ç”¨åœºæ™¯

æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªé‡è¦åº”ç”¨å°±æ˜¯**æ–‡æ¡£çš„è‡ªåŠ¨åˆ†ç±»**ã€‚

åœ¨æ–‡æ¡£åˆ†ç±»ä¸­ï¼Œæ•´ä¸ªæ–‡æ¡£ï¼ˆå¦‚ä¸€å°ç”µå­é‚®ä»¶ï¼‰æ˜¯å®ä¾‹ï¼Œè€Œç”µå­é‚®ä»¶ä¸­çš„æŸäº›å…ƒç´ åˆ™æ„æˆç‰¹å¾ã€‚æˆ‘ä»¬å¯ä»¥è§‚å¯Ÿæ–‡æ¡£ä¸­å‡ºç°çš„è¯ï¼Œå¹¶æŠŠæ¯ä¸ªè¯ä½œä¸ºä¸€ä¸ªç‰¹å¾ï¼Œè€Œæ¯ä¸ªè¯çš„å‡ºç°æˆ–è€…ä¸å‡ºç°ä½œä¸ºè¯¥ç‰¹å¾çš„å€¼ï¼Œè¿™æ ·å¾—åˆ°çš„ç‰¹å¾æ•°ç›®å°±ä¼šè·Ÿè¯æ±‡è¡¨ä¸­çš„è¯çš„æ•°ç›®ä¸€æ ·å¤šã€‚

æœ´ç´ è´å¶æ–¯æ˜¯ä¸Šé¢ä»‹ç»çš„è´å¶æ–¯åˆ†ç±»å™¨çš„ä¸€ä¸ªæ‰©å±•ï¼Œæ˜¯ç”¨äºæ–‡æ¡£åˆ†ç±»çš„å¸¸ç”¨ç®—æ³•ã€‚ä¸‹é¢æˆ‘ä»¬ä¼šè¿›è¡Œä¸€äº›æœ´ç´ è´å¶æ–¯åˆ†ç±»çš„å®è·µé¡¹ç›®ã€‚

### å·¥ä½œåŸç†

- æå–æ‰€æœ‰æ–‡æ¡£ä¸­çš„è¯æ¡å¹¶è¿›è¡Œå»é‡ 

- è·å–æ–‡æ¡£çš„æ‰€æœ‰ç±»åˆ« 

- è®¡ç®—æ¯ä¸ªç±»åˆ«ä¸­çš„æ–‡æ¡£æ•°ç›® 

- å¯¹æ¯ç¯‡è®­ç»ƒæ–‡æ¡£:     

â€‹	å¯¹æ¯ä¸ªç±»åˆ«:         

â€‹		å¦‚æœè¯æ¡å‡ºç°åœ¨æ–‡æ¡£ä¸­-->å¢åŠ è¯¥è¯æ¡çš„è®¡æ•°å€¼ï¼ˆforå¾ªç¯æˆ–è€…çŸ©é˜µç›¸åŠ ï¼‰        

â€‹		å¢åŠ æ‰€æœ‰è¯æ¡çš„è®¡æ•°å€¼ï¼ˆæ­¤ç±»åˆ«ä¸‹è¯æ¡æ€»æ•°ï¼‰ 

- å¯¹æ¯ä¸ªç±»åˆ«:     

â€‹	å¯¹æ¯ä¸ªè¯æ¡:         

â€‹		å°†è¯¥è¯æ¡çš„æ•°ç›®é™¤ä»¥æ€»è¯æ¡æ•°ç›®å¾—åˆ°çš„æ¡ä»¶æ¦‚ç‡ï¼ˆP(è¯æ¡|ç±»åˆ«)ï¼‰ 

- è¿”å›è¯¥æ–‡æ¡£å±äºæ¯ä¸ªç±»åˆ«çš„æ¡ä»¶æ¦‚ç‡ï¼ˆP(ç±»åˆ«|æ–‡æ¡£çš„æ‰€æœ‰è¯æ¡)ï¼‰

### å¼€å‘æµç¨‹

1. 
   æ”¶é›†æ•°æ®: å¯ä»¥ä½¿ç”¨ä»»ä½•æ–¹æ³•ã€‚

2. å‡†å¤‡æ•°æ®: éœ€è¦æ•°å€¼å‹æˆ–è€…å¸ƒå°”å‹æ•°æ®ã€‚

3. åˆ†ææ•°æ®: æœ‰å¤§é‡ç‰¹å¾æ—¶ï¼Œç»˜åˆ¶ç‰¹å¾ä½œç”¨ä¸å¤§ï¼Œæ­¤æ—¶ä½¿ç”¨ç›´æ–¹å›¾æ•ˆæœæ›´å¥½ã€‚

4. è®­ç»ƒç®—æ³•: è®¡ç®—ä¸åŒçš„ç‹¬ç«‹ç‰¹å¾çš„æ¡ä»¶æ¦‚ç‡ã€‚

5. æµ‹è¯•ç®—æ³•: è®¡ç®—é”™è¯¯ç‡ã€‚

6. ä½¿ç”¨ç®—æ³•: ä¸€ä¸ªå¸¸è§çš„æœ´ç´ è´å¶æ–¯åº”ç”¨æ˜¯æ–‡æ¡£åˆ†ç±»ã€‚å¯ä»¥åœ¨ä»»æ„çš„åˆ†ç±»åœºæ™¯ä¸­ä½¿ç”¨æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼Œä¸ä¸€å®šéè¦æ˜¯æ–‡æœ¬ã€‚


### ç®—æ³•ç‰¹ç‚¹

- ä¼˜ç‚¹: åœ¨æ•°æ®è¾ƒå°‘çš„æƒ…å†µä¸‹ä»ç„¶æœ‰æ•ˆï¼Œå¯ä»¥å¤„ç†å¤šç±»åˆ«é—®é¢˜ã€‚ 
- ç¼ºç‚¹: å¯¹äºè¾“å…¥æ•°æ®çš„å‡†å¤‡æ–¹å¼è¾ƒä¸ºæ•æ„Ÿã€‚ 
- é€‚ç”¨æ•°æ®ç±»å‹: æ ‡ç§°å‹æ•°æ®ã€‚

## äº”ã€é¡¹ç›®æ¡ˆä¾‹1: å±è”½ç¤¾åŒºç•™è¨€æ¿çš„ä¾®è¾±æ€§è¨€è®º

### é¡¹ç›®æ¦‚è¿°

æ„å»ºä¸€ä¸ªå¿«é€Ÿè¿‡æ»¤å™¨æ¥å±è”½åœ¨çº¿ç¤¾åŒºç•™è¨€æ¿ä¸Šçš„ä¾®è¾±æ€§è¨€è®ºã€‚å¦‚æœæŸæ¡ç•™è¨€ä½¿ç”¨äº†è´Ÿé¢æˆ–è€…ä¾®è¾±æ€§çš„è¯­è¨€ï¼Œé‚£ä¹ˆå°±å°†è¯¥ç•™è¨€æ ‡è¯†ä¸ºå†…å®¹ä¸å½“ã€‚å¯¹æ­¤é—®é¢˜å»ºç«‹ä¸¤ä¸ªç±»åˆ«: ä¾®è¾±ç±»å’Œéä¾®è¾±ç±»ï¼Œä½¿ç”¨ 1 å’Œ 0 åˆ†åˆ«è¡¨ç¤ºã€‚

å…·ä½“ä»£ç ï¼š[https://github.com/yijunquan-afk/machine-learning/blob/master/basic-learn/04-naive-bayesian/code/Naive_Bayesian_project1.py](https://github.com/yijunquan-afk/machine-learning/blob/master/basic-learn/04-plain-bayesian/code/Naive_Bayesian_project1.py)

### å¼€å‘æµç¨‹

- æ”¶é›†æ•°æ®: å¯ä»¥ä½¿ç”¨ä»»ä½•æ–¹æ³• 
- å‡†å¤‡æ•°æ®: ä»æ–‡æœ¬ä¸­æ„å»ºè¯å‘é‡ 
- åˆ†ææ•°æ®: æ£€æŸ¥è¯æ¡ç¡®ä¿è§£æçš„æ­£ç¡®æ€§ 
- è®­ç»ƒç®—æ³•: ä»è¯å‘é‡è®¡ç®—æ¦‚ç‡ 
- æµ‹è¯•ç®—æ³•: æ ¹æ®ç°å®æƒ…å†µä¿®æ”¹åˆ†ç±»å™¨ 
- ä½¿ç”¨ç®—æ³•: å¯¹ç¤¾åŒºç•™è¨€æ¿è¨€è®ºè¿›è¡Œåˆ†ç±»

### æ”¶é›†æ•°æ®

ä½¿ç”¨ç®€å•çš„æ•°æ®é›†ï¼š





```python
from numpy import *
def loadDataSet():
    """åˆ›å»ºæ•°æ®é›†

    Returns:
        postingList: å•è¯åˆ—è¡¨
        classVec   : æ‰€å±ç±»åˆ«
    """    
    postingList = [['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'], #[0,0,1,1,1......]
                   ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],
                   ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],
                   ['stop', 'posting', 'stupid', 'worthless', 'garbage'],
                   ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],
                   ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]
    classVec = [0, 1, 0, 1, 0, 1]  # 1ä¸ºæ­£ä¾‹
    return postingList, classVec    
```

### å‡†å¤‡æ•°æ®

åˆ©ç”¨è¯è¢‹æ¨¡å‹å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡

Bag of Words(BoW): å°†æ–‡æœ¬è½¬åŒ–ä¸ºå‘é‡

å¦‚å°†ä¸‹è¾¹çš„ä¸¤ä¸ªå¥å­å½“ä½œæ–‡æœ¬åº“ï¼š

```
Each state has its own laws.

Every country has its own culture.
```

è¯æ±‡è¡¨ä¸º(ä¸è®¡æ ‡ç‚¹ç¬¦å·)ï¼š
```
each state has its own laws every country culture
```

åˆ™ä¸¤ä¸ªå¥å­åˆ†åˆ«è½¬åŒ–æˆäº†å¦‚ä¸‹å‘é‡ï¼š
```
(1,1,1,1,1,1,0,0,0)
(1,0,1,1,1,0,0,1,1)
```
![image-20221217120251145](https://note-image-1307786938.cos.ap-beijing.myqcloud.com/typora/image-20221217120251145.png)

å‘é‡å®šé•¿ï¼Œé•¿åº¦ä¸è¯æ±‡è¡¨é•¿åº¦ä¸€è‡´ï¼Œè¯é¢‘ä¸ºè¯åœ¨å¥ä¸­å‡ºç°çš„æ¬¡æ•°


```python
def createVocabularyList(dataSet):
    """è·å–æ‰€æœ‰å•è¯çš„é›†åˆ

    Args:
        dataSet: æ•°æ®é›†
    Returns:
        ä¸å«é‡å¤å…ƒç´ çš„å•è¯åˆ—è¡¨
    """
    voSet = set([])
    for document in dataSet:
        voSet = voSet | set(document)
    return list(voSet)

def bagofWords(voList, document):
    """ä½¿ç”¨è¯è¢‹æ¨¡å‹å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡

    Args:
        voList: è¯æ±‡è¡¨
        document: è¾“å…¥çš„å¥å­

    Returns:
        returnVec: å•è¯å‘é‡
    """
    returnVec = zeros(len(voList))
    # éå†æ–‡æ¡£ä¸­çš„æ‰€æœ‰å•è¯ï¼Œå¦‚æœå‡ºç°äº†è¯æ±‡è¡¨ä¸­çš„å•è¯ï¼Œåˆ™å°†è¾“å‡ºçš„æ–‡æ¡£å‘é‡ä¸­çš„å¯¹åº”å€¼+1
    for word in document:
        if word in voList:
            returnVec[voList.index(word)] += 1
        else:
            print("the word: %s is not in my Vocabulary!" % word)
    return returnVec   
```

### åˆ†ææ•°æ®

æ£€æŸ¥å‡½æ•°æ‰§è¡Œæƒ…å†µï¼Œæ£€æŸ¥è¯è¡¨ï¼Œä¸å‡ºç°é‡å¤å•è¯ã€‚


```python
data,label = loadDataSet()
voList = createVocabularyList(data)
print(voList)
```

    ['how', 'garbage', 'to', 'flea', 'posting', 'steak', 'so', 'I', 'mr', 'him', 'love', 'ate', 'quit', 'dog', 'take', 'has', 'cute', 'licks', 'please', 'stop', 'food', 'buying', 'not', 'park', 'worthless', 'maybe', 'my', 'dalmation', 'problems', 'is', 'help', 'stupid']
    


```python
# å¯¹æ–‡æ¡£'my', 'dog', 'has', 'flea', 'problems', 'help', 'please'æ„å»ºå‘é‡
bagofWords(voList=voList, document = data[0])
```




    array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,
           0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0.])



å¯è§è¯å‘é‡æ„å»ºæˆåŠŸ

### è®­ç»ƒç®—æ³•

ä»è¯å‘é‡è®¡ç®—æ¦‚ç‡

ç°åœ¨å·²ç»çŸ¥é“äº†ä¸€ä¸ªè¯æ˜¯å¦å‡ºç°åœ¨ä¸€ç¯‡æ–‡æ¡£ä¸­ï¼Œä¹ŸçŸ¥é“è¯¥æ–‡æ¡£æ‰€å±çš„ç±»åˆ«ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬é‡å†™è´å¶æ–¯å‡†åˆ™ï¼Œå°†ä¹‹å‰çš„ x, y æ›¿æ¢ä¸º w. ç²—ä½“çš„ w è¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªå‘é‡ï¼Œå³å®ƒç”±å¤šä¸ªå€¼ç»„æˆã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæ•°å€¼ä¸ªæ•°ä¸è¯æ±‡è¡¨ä¸­çš„è¯ä¸ªæ•°ç›¸åŒã€‚

$$
p(c_i|\pmb w)=\frac{p(\pmb w|c_i)p(c_i)}{p(\pmb w)}
$$

æˆ‘ä»¬ä½¿ç”¨ä¸Šè¿°å…¬å¼ï¼Œå¯¹æ¯ä¸ªç±»è®¡ç®—è¯¥å€¼ï¼Œç„¶åæ¯”è¾ƒè¿™ä¸¤ä¸ªæ¦‚ç‡å€¼çš„å¤§å°ã€‚

å¯¹äºæ¯ä¸ª$c_i$ï¼Œ$P(w)$æ˜¯å›ºå®šçš„ã€‚å¹¶ä¸”æˆ‘ä»¬åªéœ€è¦æ¯”è¾ƒå·¦è¾¹å¼å­å€¼çš„å¤§å°æ¥å†³ç­–åˆ†ç±»ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±å¯ä»¥ç®€åŒ–ä¸ºé€šè¿‡æ¯”è¾ƒå³è¾¹åˆ†å­å€¼å¾—å¤§å°æ¥åšå†³ç­–åˆ†ç±»ã€‚

é¦–å…ˆå¯ä»¥é€šè¿‡ç±»åˆ« $i$ (ä¾®è¾±æ€§ç•™è¨€æˆ–è€…éä¾®è¾±æ€§ç•™è¨€)ä¸­çš„æ–‡æ¡£æ•°é™¤ä»¥æ€»çš„æ–‡æ¡£æ•°æ¥è®¡ç®—æ¦‚ç‡ $p(c_i)$ ã€‚æ¥ä¸‹æ¥è®¡ç®— $p(w | ci)$ ï¼Œè¿™é‡Œå°±è¦ç”¨åˆ°æœ´ç´ è´å¶æ–¯å‡è®¾ã€‚å¦‚æœå°† w å±•å¼€ä¸ºä¸€ä¸ªä¸ªç‹¬ç«‹ç‰¹å¾ï¼Œé‚£ä¹ˆå°±å¯ä»¥å°†ä¸Šè¿°æ¦‚ç‡å†™ä½œ $p(w_0, w_1, w_2...w_n | c_i)$ ã€‚è¿™é‡Œå‡è®¾æ‰€æœ‰è¯éƒ½äº’ç›¸ç‹¬ç«‹ï¼Œè¯¥å‡è®¾ä¹Ÿç§°ä½œæ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾ï¼ˆä¾‹å¦‚ A å’Œ B ä¸¤ä¸ªäººæŠ›éª°å­ï¼Œæ¦‚ç‡æ˜¯äº’ä¸å½±å“çš„ï¼Œä¹Ÿå°±æ˜¯ç›¸äº’ç‹¬ç«‹çš„ï¼ŒA æŠ› 2ç‚¹çš„åŒæ—¶ B æŠ› 3 ç‚¹çš„æ¦‚ç‡å°±æ˜¯ 1/6 * 1/6ï¼‰ï¼Œå®ƒæ„å‘³ç€å¯ä»¥ä½¿ç”¨ $p(w_0 | c_i)p(w_1 | c_i)p(w_2 | c_i)...p(w_n | c_i)$ æ¥è®¡ç®—ä¸Šè¿°æ¦‚ç‡ï¼Œè¿™æ ·å°±æå¤§åœ°ç®€åŒ–äº†è®¡ç®—çš„è¿‡ç¨‹ã€‚

åœ¨åˆ©ç”¨è´å¶æ–¯åˆ†ç±»å™¨å¯¹æ–‡æ¡£è¿›è¡Œåˆ†ç±»æ—¶ï¼Œè¦è®¡ç®—å¤šä¸ªæ¦‚ç‡çš„ä¹˜ç§¯ä»¥è·å¾—æ–‡æ¡£å±äºæŸä¸ªç±»åˆ«çš„æ¦‚ç‡ï¼Œå³è®¡ç®— $p(w_0|1) * p(w_1|1) * p(w_2|1)$ã€‚å¦‚æœå…¶ä¸­ä¸€ä¸ªæ¦‚ç‡å€¼ä¸º 0ï¼Œé‚£ä¹ˆæœ€åçš„ä¹˜ç§¯ä¹Ÿä¸º 0ã€‚ä¸ºé™ä½è¿™ç§å½±å“ï¼Œå¯ä»¥å°†æ‰€æœ‰è¯çš„å‡ºç°æ•°åˆå§‹åŒ–ä¸º 1ï¼Œå¹¶å°†åˆ†æ¯åˆå§‹åŒ–ä¸º 2 â€”â€”**ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯æ ¡æ­£**ã€‚

å¦ä¸€ä¸ªé‡åˆ°çš„é—®é¢˜æ˜¯ä¸‹æº¢å‡ºï¼Œè¿™æ˜¯ç”±äºå¤ªå¤šå¾ˆå°çš„æ•°ç›¸ä¹˜é€ æˆçš„ã€‚å½“è®¡ç®—ä¹˜ç§¯ $p(w_0|c_i) * p(w_1|c_i) * p(w_2|c_i)... p(w_n|_ci)$æ—¶ï¼Œç”±äºå¤§éƒ¨åˆ†å› å­éƒ½éå¸¸å°ï¼Œæ‰€ä»¥ç¨‹åºä¼šä¸‹æº¢å‡ºæˆ–è€…å¾—åˆ°ä¸æ­£ç¡®çš„ç­”æ¡ˆã€‚ï¼ˆç”¨ Python å°è¯•ç›¸ä¹˜è®¸å¤šå¾ˆå°çš„æ•°ï¼Œæœ€åå››èˆäº”å…¥åä¼šå¾—åˆ° 0ï¼‰ã€‚ä¸€ç§è§£å†³åŠæ³•æ˜¯å¯¹ä¹˜ç§¯å–è‡ªç„¶å¯¹æ•°ã€‚åœ¨ä»£æ•°ä¸­æœ‰ $ln(a * b) = ln(a) + ln(b)$, äºæ˜¯é€šè¿‡æ±‚å¯¹æ•°å¯ä»¥é¿å…ä¸‹æº¢å‡ºæˆ–è€…æµ®ç‚¹æ•°èˆå…¥å¯¼è‡´çš„é”™è¯¯ã€‚åŒæ—¶ï¼Œé‡‡ç”¨è‡ªç„¶å¯¹æ•°è¿›è¡Œå¤„ç†ä¸ä¼šæœ‰ä»»ä½•æŸå¤±ã€‚

ä¸‹å›¾ç»™å‡ºäº†å‡½æ•° f(x) ä¸ ln(f(x)) çš„æ›²çº¿ã€‚å¯ä»¥çœ‹å‡ºï¼Œå®ƒä»¬åœ¨ç›¸åŒåŒºåŸŸå†…åŒæ—¶å¢åŠ æˆ–è€…å‡å°‘ï¼Œå¹¶ä¸”åœ¨ç›¸åŒç‚¹ä¸Šå–åˆ°æå€¼ã€‚å®ƒä»¬çš„å–å€¼è™½ç„¶ä¸åŒï¼Œä½†ä¸å½±å“æœ€ç»ˆç»“æœã€‚

![image.png](attachment:image.png)


```python
def trainNB(trainMatrix, trainLabel):
    """è®­ç»ƒæ•°æ®

    Args:
        trainMatrix (çŸ©é˜µ): æ–‡æ¡£å•è¯çŸ©é˜µ [[1,0,1,1,1....],[],[]...]
        trainLabel (å‘é‡): æ–‡æ¡£ç±»åˆ«çŸ©é˜µ [0,1,1,0....]
    """
    # æ€»æ–‡ä»¶æ•°
    numTrainDocs = len(trainMatrix)
    # æ€»å•è¯æ•°
    numWords = len(trainMatrix[0])

    # ä¾®è¾±æ€§æ–‡ä»¶çš„å‡ºç°æ¦‚ç‡ï¼Œå³trainLabelä¸­æ‰€æœ‰çš„1çš„ä¸ªæ•°ï¼Œ
    # ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘æ ¡æ­£
    pc_1 = sum(trainLabel) / float(numTrainDocs)

    # æ„é€ å•è¯å‡ºç°æ¬¡æ•°åˆ—è¡¨
    p0Num = zeros(numWords)  
    p1Num = zeros(numWords)

    # æ•´ä¸ªæ•°æ®é›†å•è¯å‡ºç°æ€»æ•°
    p0Denom = 0.0
    p1Denom = 0.0

    for doc in range(numTrainDocs):
        if trainLabel[doc] == 1:
            # è¯åœ¨ç±»ä¸­å‡ºç°çš„æ¬¡æ•°
            p1Num += trainMatrix[doc]
            # ç±»ä¸­çš„æ€»è¯æ•°
            p1Denom += sum(trainMatrix[doc])
        else:
            p0Num += trainMatrix[doc]
            p0Denom += sum(trainMatrix[doc])
    # ä½¿ç”¨logé¿å…ç´¯ä¹˜æ•°å¤ªå°
    # ç±»åˆ«1çš„æ¦‚ç‡å‘é‡ï¼Œä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘æ ¡æ­£
    p1Vect = log(p1Num + 1  / p1Denom + 2)
    # ç±»åˆ«0çš„æ¦‚ç‡å‘é‡ï¼Œä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘æ ¡æ­£
    p0Vect = log(p0Num + 1 / p0Denom + 2)
    return p0Vect, p1Vect, pc_1  
```

### æµ‹è¯•ç®—æ³•


```python
def classifyNB(inputData, p0Vec, p1Vec, pClass1):
    """ä½¿ç”¨æœ´ç´ è´å¶æ–¯è¿›è¡Œåˆ†ç±»

    Args:
        inputData (å‘é‡): å¾…åˆ†ç±»çš„æ•°æ®
        p0Vec (å‘é‡): ç±»åˆ«1çš„æ¦‚ç‡å‘é‡
        p1Vec (å‘é‡): ç±»åˆ«2çš„æ¦‚ç‡å‘é‡
        pClass1 (æ•°): ç±»åˆ«1æ–‡æ¡£çš„å‡ºç°æ¦‚ç‡

    Returns:
        æ•°: åˆ†ç±»ç»“æœ
    """  
    # logçš„ä½¿ç”¨ä½¿ä¹˜æ³•å˜ä¸ºå®¶æ³•  
    # ä½¿ç”¨ NumPy æ•°ç»„æ¥è®¡ç®—ä¸¤ä¸ªå‘é‡ç›¸ä¹˜çš„ç»“æœï¼Œè¿™é‡Œçš„ç›¸ä¹˜æ˜¯æŒ‡å¯¹åº”å…ƒç´ ç›¸ä¹˜ï¼Œ
    # å³å…ˆå°†ä¸¤ä¸ªå‘é‡ä¸­çš„ç¬¬ä¸€ä¸ªå…ƒç´ ç›¸ä¹˜ï¼Œç„¶åå°†ç¬¬2ä¸ªå…ƒç´ ç›¸ä¹˜ï¼Œä»¥æ­¤ç±»æ¨ã€‚
    # è¿™é‡Œçš„ inputData * p1Vec çš„æ„æ€å°±æ˜¯å°†æ¯ä¸ªè¯ä¸å…¶å¯¹åº”çš„æ¦‚ç‡ç›¸å…³è”èµ·æ¥
    p1 = sum(inputData * p1Vec) + log(pClass1) # P(w|c1) * P(c1) ï¼Œå³è´å¶æ–¯å‡†åˆ™çš„åˆ†å­
    p0 = sum(inputData * p0Vec) + log(1.0 - pClass1) # P(w|c0) * P(c0) ï¼Œå³è´å¶æ–¯å‡†åˆ™çš„åˆ†å­Â·
    if p1 > p0:
        return 1
    else:
        return 0


def testingNB():
    """
    æµ‹è¯•æœ´ç´ è´å¶æ–¯ç®—æ³•
    """
    # 1. åŠ è½½æ•°æ®é›†
    listOPosts, listClasses = loadDataSet()
    # 2. åˆ›å»ºå•è¯é›†åˆ
    myVocabList = createVocabularyList(listOPosts)
    # 3. è®¡ç®—å•è¯æ˜¯å¦å‡ºç°å¹¶åˆ›å»ºæ•°æ®çŸ©é˜µ
    trainMat = []
    for postinDoc in listOPosts:
        # è¿”å›m*len(myVocabList)çš„çŸ©é˜µï¼Œ è®°å½•çš„éƒ½æ˜¯0ï¼Œ1ä¿¡æ¯
        trainMat.append(bagofWords(myVocabList, postinDoc))
    # 4. è®­ç»ƒæ•°æ®
    p0V, p1V, pAb = trainNB(array(trainMat), array(listClasses))
    # 5. æµ‹è¯•æ•°æ®
    testEntry = ['love', 'my', 'dalmation']
    thisDoc = array(bagofWords(myVocabList, testEntry))
    print( testEntry, 'classified as: ', classifyNB(thisDoc, p0V, p1V, pAb))
    testEntry = ['stupid', 'garbage']
    thisDoc = array(bagofWords(myVocabList, testEntry))
    print (testEntry, 'classified as: ', classifyNB(thisDoc, p0V, p1V, pAb))

testingNB()
```

    ['love', 'my', 'dalmation'] classified as:  0
    ['stupid', 'garbage'] classified as:  1
    

## å…­ã€é¡¹ç›®æ¡ˆä¾‹2: è¿‡æ»¤åƒåœ¾é‚®ä»¶

### é¡¹ç›®æ¦‚è¿°

å®Œæˆæœ´ç´ è´å¶æ–¯çš„ä¸€ä¸ªæœ€è‘—åçš„åº”ç”¨: ç”µå­é‚®ä»¶åƒåœ¾è¿‡æ»¤ã€‚

å…·ä½“ä»£ç ï¼š[https://github.com/yijunquan-afk/machine-learning/blob/master/basic-learn/04-naive-bayesian/code/Naive_Bayesian_project2.py](https://github.com/yijunquan-afk/machine-learning/blob/master/basic-learn/04-plain-bayesian/code/Naive_Bayesian_project2.py)

### å¼€å‘æµç¨‹

1ã€æ”¶é›†æ•°æ®: æä¾›æ–‡æœ¬æ–‡ä»¶

2ã€å‡†å¤‡æ•°æ®: å°†æ–‡æœ¬æ–‡ä»¶è§£ææˆè¯æ¡å‘é‡

3ã€åˆ†ææ•°æ®: æ£€æŸ¥è¯æ¡ç¡®ä¿è§£æçš„æ­£ç¡®æ€§

4ã€è®­ç»ƒç®—æ³•: ä½¿ç”¨æˆ‘ä»¬ä¹‹å‰å»ºç«‹çš„ trainNB() å‡½æ•°

5ã€æµ‹è¯•ç®—æ³•: ä½¿ç”¨æœ´ç´ è´å¶æ–¯è¿›è¡Œäº¤å‰éªŒè¯

6ã€ä½¿ç”¨ç®—æ³•: æ„å»ºä¸€ä¸ªå®Œæ•´çš„ç¨‹åºå¯¹ä¸€ç»„æ–‡æ¡£è¿›è¡Œåˆ†ç±»ï¼Œå°†é”™åˆ†çš„æ–‡æ¡£è¾“å‡ºåˆ°å±å¹•ä¸Š

### æ”¶é›†æ•°æ®

é‚®ä»¶çš„æ–‡æœ¬æ–‡ä»¶å½¢å¼å¦‚ä¸‹ï¼š
```
Hi Peter,

With Jose out of town, do you want to
meet once in a while to keep things
going and do some interesting stuff?

Let me know
Eugene
```
å…¨éƒ¨çš„æ•°æ®å­˜å‚¨åœ¨[https://github.com/yijunquan-afk/machine-learning/tree/master/basic-learn/04-plain-bayesian/data/4.NaiveBayes/email](https://github.com/yijunquan-afk/machine-learning/tree/master/basic-learn/04-plain-bayesian/data/4.NaiveBayes/email)ä¸­

### å‡†å¤‡æ•°æ®

å°†æ–‡æœ¬æ–‡ä»¶è§£ææˆè¯æ¡å‘é‡ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¥åˆ‡åˆ†æ–‡æœ¬ã€‚


```python
import re
def textParse(inputString):
    '''æ¥æ”¶ä¸€ä¸ªå¤§å­—ç¬¦ä¸²å¹¶å°†å…¶è§£æä¸ºå­—ç¬¦ä¸²åˆ—è¡¨
    Args:
        inputString -- å¤§å­—ç¬¦ä¸²
    Returns:
        å»æ‰å°‘äº 2 ä¸ªå­—ç¬¦çš„å­—ç¬¦ä¸²ï¼Œå¹¶å°†æ‰€æœ‰å­—ç¬¦ä¸²è½¬æ¢ä¸ºå°å†™ï¼Œè¿”å›å­—ç¬¦ä¸²åˆ—è¡¨
    '''

    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¥åˆ‡åˆ†å¥å­ï¼Œå…¶ä¸­åˆ†éš”ç¬¦æ˜¯é™¤å•è¯ã€æ•°å­—å¤–çš„ä»»æ„å­—ç¬¦ä¸²
    listOfTokens = re.split(r'\W+', inputString)
    return [tok.lower() for tok in listOfTokens if len(tok) > 2]
```


```python
# æµ‹è¯•ä¸€ä¸‹
mySent = 'This book is the best book on Python or M.L. I have ever laid eyes upon.'
print(textParse(mySent))
```

    ['this', 'book', 'the', 'best', 'book', 'python', 'have', 'ever', 'laid', 'eyes', 'upon']
    

### åˆ†ææ•°æ®

å’Œé¡¹ç›®1ä¸€æ ·

### è®­ç»ƒç®—æ³•

ä½¿ç”¨é¡¹ç›®1çš„å‡½æ•°`trainNB()`è¿›è¡Œè®­ç»ƒ


```python
def trainNB(trainMatrix, trainLabel):
    """è®­ç»ƒæ•°æ®

    Args:
        trainMatrix (çŸ©é˜µ): æ–‡æ¡£å•è¯çŸ©é˜µ [[1,0,1,1,1....],[],[]...]
        trainLabel (å‘é‡): æ–‡æ¡£ç±»åˆ«çŸ©é˜µ [0,1,1,0....]
    """
    # æ€»æ–‡ä»¶æ•°
    numTrainDocs = len(trainMatrix)
    # æ€»å•è¯æ•°
    numWords = len(trainMatrix[0])

    # ä¾®è¾±æ€§æ–‡ä»¶çš„å‡ºç°æ¦‚ç‡ï¼Œå³trainLabelä¸­æ‰€æœ‰çš„1çš„ä¸ªæ•°ï¼Œ
    # ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘æ ¡æ­£
    pc_1 = sum(trainLabel) / float(numTrainDocs)

    # æ„é€ å•è¯å‡ºç°æ¬¡æ•°åˆ—è¡¨
    p0Num = zeros(numWords)  
    p1Num = zeros(numWords)

    # æ•´ä¸ªæ•°æ®é›†å•è¯å‡ºç°æ€»æ•°
    p0Denom = 0.0
    p1Denom = 0.0

    for doc in range(numTrainDocs):
        if trainLabel[doc] == 1:
            # è¯åœ¨ç±»ä¸­å‡ºç°çš„æ¬¡æ•°
            p1Num += trainMatrix[doc]
            # ç±»ä¸­çš„æ€»è¯æ•°
            p1Denom += sum(trainMatrix[doc])
        else:
            p0Num += trainMatrix[doc]
            p0Denom += sum(trainMatrix[doc])
    # ä½¿ç”¨logé¿å…ç´¯ä¹˜æ•°å¤ªå°
    # ç±»åˆ«1çš„æ¦‚ç‡å‘é‡ï¼Œä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘æ ¡æ­£
    p1Vect = log(p1Num + 1  / p1Denom + 2)
    # ç±»åˆ«0çš„æ¦‚ç‡å‘é‡ï¼Œä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘æ ¡æ­£
    p0Vect = log(p0Num + 1 / p0Denom + 2)
    return p0Vect, p1Vect, pc_1  
```

### æµ‹è¯•ç®—æ³•

ä½¿ç”¨æœ´ç´ è´å¶æ–¯è¿›è¡Œäº¤å‰éªŒè¯

#### äº¤å‰éªŒè¯

é—®é¢˜ï¼šæ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®ç•™å‡ºä¸€ä¸ªæµ‹è¯•é›†

æ–¹æ¡ˆï¼šæ¯ä¸€ä¸ªæ•°æ®æ—¢è¢«å½“ä½œè®­ç»ƒæ ·æœ¬ä¹Ÿè¢«å½“ä½œæµ‹è¯•æ ·æœ¬

![image-20220317111039287](https://note-image-1307786938.cos.ap-beijing.myqcloud.com/typora/qshell/image-20220317111039287.png)

**çº¿æ€§å›å½’ä¸€ç»´ä¾‹å­**ï¼š

> å°†æ•°æ®åˆ†æˆç´«ã€ç»¿ã€è“ä¸‰ä¸ªå­é›†
>
> å¯¹äºè“è‰²åˆ’åˆ†ï¼šä½¿ç”¨ç´«ã€ç»¿æ•°æ®è®­ç»ƒçº¿æ€§æ¨¡å‹ï¼Œä½¿ç”¨è“è‰²æ•°æ®è®¡ç®—å‡æ–¹è¯¯å·®
>
> å¯¹äºç»¿è‰²åˆ’åˆ†ï¼šä½¿ç”¨ç´«ã€è“æ•°æ®è®­ç»ƒçº¿æ€§æ¨¡å‹ï¼Œä½¿ç”¨ç»¿è‰²æ•°æ®è®¡ç®—å‡æ–¹è¯¯å·®
>
> å¯¹äºç´«è‰²åˆ’åˆ†ï¼šä½¿ç”¨ç»¿ã€è“æ•°æ®è®­ç»ƒçº¿æ€§æ¨¡å‹ï¼Œä½¿ç”¨ç´«è‰²æ•°æ®è®¡ç®—å‡æ–¹è¯¯å·®
>
> ![image-20220317111411016](https://note-image-1307786938.cos.ap-beijing.myqcloud.com/typora/qshell/image-20220317111411016.png)

## 


```python
def spamTest():
    """äº¤å‰éªŒè¯
    """
    docList = []
    classList = []
    fullText = []
    for i in range(1, 26):
        # åˆ‡åˆ†ï¼Œè§£ææ•°æ®ï¼Œå¹¶å½’ç±»ä¸º 1 ç±»åˆ«
        wordList = textParse(
            open('data/4.NaiveBayes/email/spam/%d.txt' % i,
                 'r',
                 encoding='utf-8').read())
        docList.append(wordList)
        classList.append(1)
        # åˆ‡åˆ†ï¼Œè§£ææ•°æ®ï¼Œå¹¶å½’ç±»ä¸º 0 ç±»åˆ«
        wordList = textParse(
            open('data/4.NaiveBayes/email/ham/%d.txt' % i,
                 'r',
                 encoding='utf-8').read())
        docList.append(wordList)
        fullText.extend(wordList)
        classList.append(0)
    vocabList = createVocabularyList(docList)  #åˆ›å»ºè¯æ±‡è¡¨ï¼Œä¸é‡å¤
    trainingSet = list(range(50))
    testSet = []  #åˆ›å»ºå­˜å‚¨è®­ç»ƒé›†çš„ç´¢å¼•å€¼çš„åˆ—è¡¨å’Œæµ‹è¯•é›†çš„ç´¢å¼•å€¼çš„åˆ—è¡¨
    for i in range(10):  #ä»50ä¸ªé‚®ä»¶ä¸­ï¼ŒéšæœºæŒ‘é€‰å‡º40ä¸ªä½œä¸ºè®­ç»ƒé›†,10ä¸ªåšæµ‹è¯•é›†
        randIndex = int(random.uniform(0, len(trainingSet)))  #éšæœºé€‰å–ç´¢ç´¢å¼•å€¼
        testSet.append(trainingSet[randIndex])  #æ·»åŠ æµ‹è¯•é›†çš„ç´¢å¼•å€¼
        del (trainingSet[randIndex])  #åœ¨è®­ç»ƒé›†åˆ—è¡¨ä¸­åˆ é™¤æ·»åŠ åˆ°æµ‹è¯•é›†çš„ç´¢å¼•å€¼
    trainMat = []
    trainClasses = []  #åˆ›å»ºè®­ç»ƒé›†çŸ©é˜µå’Œè®­ç»ƒé›†ç±»åˆ«æ ‡ç­¾ç³»å‘é‡
    for docIndex in trainingSet:  #éå†è®­ç»ƒé›†
        trainMat.append(bagofWords(vocabList,
                                   docList[docIndex]))  #å°†ç”Ÿæˆçš„è¯é›†æ¨¡å‹æ·»åŠ åˆ°è®­ç»ƒçŸ©é˜µä¸­
        trainClasses.append(classList[docIndex])  #å°†ç±»åˆ«æ·»åŠ åˆ°è®­ç»ƒé›†ç±»åˆ«æ ‡ç­¾ç³»å‘é‡ä¸­
    p0V, p1V, pSpam = trainNB(array(trainMat), array(trainClasses))  #è®­ç»ƒæœ´ç´ è´å¶æ–¯æ¨¡å‹
    errorCount = 0  #é”™è¯¯åˆ†ç±»è®¡æ•°
    for docIndex in testSet:  #éå†æµ‹è¯•é›†
        wordVector = bagofWords(vocabList, docList[docIndex])  #æµ‹è¯•é›†çš„è¯é›†æ¨¡å‹
        if classifyNB(array(wordVector), p0V, p1V, pSpam) != classList[docIndex]:  #å¦‚æœåˆ†ç±»é”™è¯¯
            errorCount += 1  #é”™è¯¯è®¡æ•°åŠ 1
            print("åˆ†ç±»é”™è¯¯çš„æµ‹è¯•é›†ï¼š", docList[docIndex])
    print('é”™è¯¯ç‡ï¼š%.2f%%' % (float(errorCount) / len(testSet) * 100))
```


```python
spamTest()
```

    åˆ†ç±»é”™è¯¯çš„æµ‹è¯•é›†ï¼š ['home', 'based', 'business', 'opportunity', 'knocking', 'your', 'door', 'don', 'rude', 'and', 'let', 'this', 'chance', 'you', 'can', 'earn', 'great', 'income', 'and', 'find', 'your', 'financial', 'life', 'transformed', 'learn', 'more', 'here', 'your', 'success', 'work', 'from', 'home', 'finder', 'experts']
    é”™è¯¯ç‡ï¼š10.00%
    
